{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd6fd483-427d-4378-9383-7c62dd7d6af2",
   "metadata": {},
   "source": [
    "## This is the coding problem w.r.t. Chapter 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e357efee-5955-4749-8437-551de3bc767d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MLE is (0.036067083938583065,0.1958034414407979,0.768129474620619)\n"
     ]
    }
   ],
   "source": [
    "c,i,t,nc,ni,nt,nu =  1/3,1/3,1/3,85,196,341,578\n",
    "n = nc+ni+nt+nu\n",
    "diff = 1\n",
    "\n",
    "while (diff>1e-5):\n",
    "    # E-step\n",
    "    ncc = nc*(c**2)/(c**2+2*c*i+2*c*t)\n",
    "    nci = nc*(2*c*i)/(c**2+2*c*i+2*c*t)\n",
    "    nct = nc*(2*c*t)/(c**2+2*c*i+2*c*t)\n",
    "    nii = ni*(i**2)/(i**2+2*i*t)+nu*(i**2)/(i**2+2*i*t+t**2)\n",
    "    nit = ni*(2*i*t)/(i**2+2*i*t)+nu*(2*i*t)/(i**2+2*i*t+t**2)\n",
    "    ntt = nt+nu*(t**2)/(i**2+2*i*t+t**2)\n",
    "    # M-step\n",
    "    c1 = (2*ncc+nci+nct)/(2*n)\n",
    "    i1 = (nci+2*nii+nit)/(2*n)\n",
    "    t1 = (nct+nit+2*ntt)/(2*n)\n",
    "    # iteration\n",
    "    diff = abs(c1-c)+abs(i1-i)+abs(t1-t)\n",
    "    c = c1\n",
    "    i = i1\n",
    "    t = t1\n",
    "    \n",
    "print(\"The MLE is ({},{},{})\".format(c,i,t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f04247e-d9de-425b-86f8-abf969f3ab70",
   "metadata": {},
   "source": [
    "在很多 EM 收敛性分析里，定义\n",
    "$$\n",
    "H(\\theta,\\theta{\\prime})\n",
    "\\;=\\;\\int \\bigl[\\log f_{X\\mid Y}(x\\mid y;\\theta)\\bigr]\\;f_{X\\mid Y}(x\\mid y;\\theta{\\prime})\\,dx.\n",
    "$$\n",
    "这就是把“$\\log f_{X\\mid Y}(x\\mid y;\\theta)$”在“$x \\sim f_{X\\mid Y}(x\\mid y;\\theta{\\prime})$”下取期望。\n",
    "\n",
    "同理，\n",
    "$$\n",
    "H(\\theta{\\prime},\\theta{\\prime})\n",
    "\\;=\\;\\int \\bigl[\\log f_{X\\mid Y}(x\\mid y;\\theta{\\prime})\\bigr]\\;f_{X\\mid Y}(x\\mid y;\\theta{\\prime})\\,dx.\n",
    "$$\n",
    "\n",
    "我们把 $p(x)=f_{X\\mid Y}(x\\mid y;\\theta{\\prime})$ 记为“参考分布”，$q(x)=f_{X\\mid Y}(x\\mid y;\\theta)$ 记为“比较分布”。那么\n",
    "\t•\t$\\displaystyle H(\\theta,\\theta{\\prime})=\\int p(x)\\log q(x)\\,dx,$\n",
    "\t•\t$\\displaystyle H(\\theta{\\prime},\\theta{\\prime})=\\int p(x)\\log p(x)\\,dx.$\n",
    "\n",
    "那么\n",
    "$$\n",
    "H(\\theta,\\theta{\\prime}) \\;-\\; H(\\theta{\\prime},\\theta{\\prime})\n",
    "\\;=\\;\\int p(x)\\log q(x)\\,dx \\;-\\;\\int p(x)\\log p(x)\\,dx\n",
    "\\;=\\;-\\int p(x)\\,\\log\\frac{p(x)}{q(x)}\\,dx.\n",
    "$$\n",
    "注意这里出现了分布 p 和 q 的 Kullback-Leibler 散度：\n",
    "$$\n",
    "\\mathrm{KL}(p\\mid\\mid q)\n",
    "\\;=\\;\\int p(x)\\,\\log\\frac{p(x)}{q(x)}\\,dx\n",
    "\\;\\ge\\; 0.\n",
    "$$\n",
    "\n",
    "因此\n",
    "$$\n",
    "H(\\theta,\\theta{\\prime}) - H(\\theta{\\prime},\\theta{\\prime})\n",
    "= -\\,\\mathrm{KL}(p\\mid\\mid q)\n",
    "\\;\\le\\; 0,\n",
    "$$\n",
    "也就意味着\n",
    "$$\n",
    "H(\\theta,\\theta{\\prime})\n",
    "\\;\\le\\;\n",
    "H(\\theta{\\prime},\\theta{\\prime}).\n",
    "$$\n",
    "\n",
    "Jensen 不等式视角：$\\mathrm{KL}(p\\mid\\mid q) \\ge 0 $等价于\n",
    "\n",
    "$$\\int p(x)\\log p(x)\\,dx \\;\\ge\\; \\int p(x)\\log q(x)\\,dx,$$\n",
    "\n",
    "这本质上就是“对数函数是凹函数”所导致的期望不等式。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec76144-7204-4a31-90ae-b92fc1d393cb",
   "metadata": {},
   "source": [
    "$$\n",
    "\\log L(\\beta)\n",
    "\\;=\\;\n",
    "\\sum_{i=1}^n\n",
    "\\Bigl[\n",
    "y_i \\,\\log \\Bigl(\\tfrac{\\exp(x_i^\\top\\beta)}{1+\\exp(x_i^\\top\\beta)}\\Bigr)\n",
    "\\;+\\;\n",
    "(1-y_i)\\,\\log \\Bigl(\\tfrac{1}{1+\\exp(x_i^\\top\\beta)}\\Bigr)\n",
    "\\Bigr].\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f6bbed-b0cf-4a25-a627-6daabc4f0b5e",
   "metadata": {},
   "source": [
    "## Ch3 Q1.\n",
    "Because $X_{1}, \\cdots, X_{n}$ are $i.i.d.$ from $N(\\theta, 4)$ distribution, $f_{X|\\theta}(X|\\theta) = \\prod\\limits_{i=1}^{n}f_{X_{i}|\\theta}(x_{i}|\\theta) = \\prod\\limits_{i=1}^{n}\\frac{1}{\\sqrt{8\\pi}}\\exp\\{-\\frac{(x_{i}-\\theta)^{2}}{8}\\}$.\\\n",
    "And the prior distribution of $\\theta$ is $N(0, 10)$, $\\pi(\\theta) = \\frac{1}{\\sqrt{20\\pi}}\\exp\\{-\\frac{\\theta^{2}}{20}\\}$. Therefore, $$\\begin{align*}\n",
    "f_{\\theta|X}(\\theta|X) &= \\frac{f_{X,\\theta}(X, \\theta)}{f_{X}(X)}=  \\frac{\\pi(\\theta)f_{X|\\theta}(X|\\theta)}{\\int\\pi(\\theta)f_{X|\\theta}(X|\\theta)d\\theta} \\\\\n",
    "&= \\frac{\\exp\\{-\\frac{\\sum\\limits_{i=1}^{n}(x_{i}-\\theta)^{2}}{8}-\\frac{\\theta^{2}}{20}\\}}{\\int \\exp\\{-\\frac{\\sum\\limits_{i=1}^{n}(x_{i}-\\theta)^{2}}{8}-\\frac{\\theta^{2}}{20}\\}d\\theta}\\\\\n",
    "&\\propto \\exp \\{ -\\frac{\\left(\\theta-\\frac{5\\sum x_i}{5n+2}\\right)^2}{2 \\cdot \\frac{20}{5n+2}} \\}\n",
    "\\end{align*}\n",
    "$$\n",
    "which is the kernel of normal distribution, thus the  posterior distribution of $\\theta$ is $N(\\frac{5\\sum x_i}{5n+2},\\frac{20}{5n+2})$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f8338c-4ced-4f48-9583-8bf34b737589",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
