{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22dd4176-4e91-48ad-a4a4-5140c521e251",
   "metadata": {},
   "source": [
    "Without using python package, write a class to implement KNN for regression. It requires to choose optimal number of neighbors with prediction errors using holdout 20% test set. You should first generate data from $Y=X_1^2-2X_2-2\\sin(X_3) + \\cos(X_4^3) +\\log(|X_5|+1) + \\epsilon,$ where $X=(X_1,X_2,X_3,X_4,X_5)$ follows normal distribution $N(0,I_5)$ and   $ \\epsilon$ follows $0.5N(0,1).$ The sample size of data is set to be $2000.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a9787356-d78f-4e07-80c1-3d4939f87c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "N = 2000\n",
    "dim = 5\n",
    "def data_generation(n,dim):\n",
    "    x = np.random.multivariate_normal(mean=np.zeros(dim), cov=np.eye(dim), size=n)\n",
    "    epi = 0.5*np.random.normal(0,1,n)\n",
    "    y = x[:,0]**2 - 2*x[:,1] - 2*np.sin(x[:,2]) + np.cos(x[:,3]**3) + np.log(np.abs(x[:,4]) + 1) + epi\n",
    "    \n",
    "    return (x, y.reshape(-1,1))\n",
    "\n",
    "def data_split(x,y,percentage = 0.2):\n",
    "    data = np.concatenate((x,y),axis=1)\n",
    "    shuffled_data = np.random.permutation(data)\n",
    "    n = len(x)\n",
    "    test_set = shuffled_data[0:int(percentage*n),:]\n",
    "    training_set = shuffled_data[int(percentage*n):,:]\n",
    "\n",
    "    return training_set, test_set\n",
    "\n",
    "def KNN_regression(data,N,a_test):\n",
    "    x = data[:,:-1]\n",
    "    y = data[:,-1]\n",
    "    dist = np.sum((a_test.reshape(1,-1) - x)**2, axis = 1)\n",
    "    indices = np.argsort(dist)[:N]  # 最小 n 个数的索引\n",
    "\n",
    "    return np.average(y[indices])\n",
    "\n",
    "def Vectorized_KNN(test,data,N):\n",
    "    f = lambda x : KNN_regression(data,N,x)\n",
    "    \n",
    "    return np.apply_along_axis(f, axis=1, arr=test)\n",
    "\n",
    "def Loss_func(prediction, original):\n",
    "    return np.sum((prediction - original)**2)\n",
    "    \n",
    "def optimal_classnum(test, training, N_list):\n",
    "    loss = []\n",
    "    for n in N_list:\n",
    "        prediction = Vectorized_KNN(test[:,:-1], training, n)\n",
    "        myloss = Loss_func(prediction, test[:,-1])\n",
    "        loss.append(myloss)\n",
    "    return N_list[np.argmin(loss)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7cbc152b-1308-45ea-b376-4df533dad703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04048564 0.53210068]\n",
      "[[ 0.33344939]\n",
      " [-0.74648381]\n",
      " [ 0.09875368]\n",
      " [ 0.14541873]\n",
      " [ 0.10421954]]\n",
      "[[ 0.15738235 -0.98675802 -0.06818563 -1.36589746 -1.90251984]\n",
      " [-0.2540199   0.64192017  2.02419165 -0.2560324  -1.13938193]\n",
      " [ 1.60241914  0.60985916 -1.23926117 -1.21393687 -0.06428513]\n",
      " ...\n",
      " [ 0.2846106  -0.89869155  0.95880913  0.71076734 -0.52064496]\n",
      " [ 1.28839516  0.72075824 -1.50128217 -0.06944642 -2.05377468]\n",
      " [-0.38431382  0.90005003  0.5568599  -0.37342675 -1.45145424]] [[ 2.13534743]\n",
      " [-0.89671747]\n",
      " [ 3.39061261]\n",
      " ...\n",
      " [ 0.39946042]\n",
      " [ 4.49208222]\n",
      " [-0.49610567]]\n",
      "(400,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.multivariate_normal(mean=np.zeros(5), cov=np.eye(5), size=2)\n",
    "a[0,:]\n",
    "print(a[:,0])\n",
    "epi = 0.5*np.random.normal(0,1,(dim,1))\n",
    "print(epi)\n",
    "\n",
    "x,y = data_generation(N,dim)\n",
    "print(x,y)\n",
    "\n",
    "training, test = data_split(x,y)\n",
    "\n",
    "KNN_regression(training,5,test[0,:-1])\n",
    "predict = Vectorized_KNN(test[:,:-1],training,5)\n",
    "print(predict.shape)\n",
    "\n",
    "loss = Loss_func(predict, test[:,-1])\n",
    "optimal_classnum(test, training,np.arange(2,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ba06e5a7-61d7-4ea9-acc8-b622105cea31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal N: 9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class KNN_Regression(object):\n",
    "    def __init__(self, sample_size, dim, num_class=None):\n",
    "        self.N = sample_size  # 样本数\n",
    "        self.dim = dim  # 特征维度\n",
    "        self.num_class = num_class  # 类别数量（如果需要）\n",
    "\n",
    "    def data_generation(self):\n",
    "        # 生成数据\n",
    "        x = np.random.multivariate_normal(mean=np.zeros(self.dim), cov=np.eye(self.dim), size=self.N)\n",
    "        epi = 0.5 * np.random.normal(0, 1, self.N)\n",
    "        y = x[:, 0]**2 - 2 * x[:, 1] - 2 * np.sin(x[:, 2]) + np.cos(x[:, 3]**3) + np.log(np.abs(x[:, 4]) + 1) + epi\n",
    "        self.x = x\n",
    "        self.y = y.reshape(-1, 1)\n",
    "\n",
    "    def data_split(self, percentage=0.2):\n",
    "        # 划分数据集为训练集和测试集\n",
    "        data = np.concatenate((self.x, self.y), axis=1)\n",
    "        shuffled_data = np.random.permutation(data)  # 随机打乱数据\n",
    "        n = len(self.x)\n",
    "        test_set = shuffled_data[:int(percentage * n), :]  # 测试集\n",
    "        training_set = shuffled_data[int(percentage * n):, :]  # 训练集\n",
    "        self.training = training_set\n",
    "        self.test = test_set\n",
    "\n",
    "    def KNN_regression(self, a_test, N):\n",
    "        # 单点的 KNN 回归\n",
    "        x_train = self.training[:, :-1]  # 训练集特征\n",
    "        y_train = self.training[:, -1]  # 训练集标签\n",
    "        dist = np.sum((a_test.reshape(1, -1) - x_train)**2, axis=1)  # 计算欧几里得距离的平方\n",
    "        indices = np.argsort(dist)[:N]  # 距离最近的 N 个点索引\n",
    "        return np.average(y_train[indices])  # 返回 N 个最近点的标签平均值\n",
    "\n",
    "    def Vectorized_KNN(self, test_features, N):\n",
    "        # 使用向量化方法对测试集进行 KNN 回归\n",
    "        f = lambda x: self.KNN_regression(x, N)  # 将单点回归函数封装为 lambda 函数\n",
    "        predictions = np.apply_along_axis(f, axis=1, arr=test_features)  # 对每个测试样本应用回归\n",
    "        return predictions\n",
    "\n",
    "    def Loss_func(self, prediction, original):\n",
    "        # 损失函数，计算平方误差\n",
    "        return np.sum((prediction - original)**2)\n",
    "\n",
    "    def optimal_classnum(self, N_list):\n",
    "        # 寻找最佳 N\n",
    "        test_features = self.test[:, :-1]\n",
    "        test_labels = self.test[:, -1]\n",
    "        loss = []\n",
    "        for n in N_list:\n",
    "            prediction = self.Vectorized_KNN(test_features, n)\n",
    "            myloss = self.Loss_func(prediction, test_labels)\n",
    "            loss.append(myloss)\n",
    "        optimal_n = N_list[np.argmin(loss)]  # 返回使损失最小的 N\n",
    "        return optimal_n\n",
    "\n",
    "\n",
    "# 使用实例\n",
    "sample = 2000\n",
    "dim = 5\n",
    "num_class = 6\n",
    "my_class = KNN_Regression(sample, dim, num_class)\n",
    "\n",
    "# 生成数据\n",
    "my_class.data_generation()\n",
    "\n",
    "# 划分数据\n",
    "my_class.data_split()\n",
    "\n",
    "# 测试 optimal_classnum\n",
    "N_list = np.arange(2,20)\n",
    "optimal_N = my_class.optimal_classnum(N_list)\n",
    "print(f\"Optimal N: {optimal_N}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3234828c-9b6e-4ba7-a71e-dd686190ebb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for a single test point: 1.3047\n",
      "Predictions for all test points:\n",
      "[1.30465923 6.30396091 1.120483   4.28986842 5.03158275]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class KNN_Regression(object):\n",
    "    def __init__(self, sample_size, dim, num_class=None):\n",
    "        self.N = sample_size  # 样本数\n",
    "        self.dim = dim  # 特征维度\n",
    "        self.num_class = num_class  # 类别数量（如果需要）\n",
    "\n",
    "    def data_generation(self):\n",
    "        # 生成数据\n",
    "        x = np.random.multivariate_normal(mean=np.zeros(self.dim), cov=np.eye(self.dim), size=self.N)\n",
    "        epi = 0.5 * np.random.normal(0, 1, self.N)\n",
    "        y = x[:, 0]**2 - 2 * x[:, 1] - 2 * np.sin(x[:, 2]) + np.cos(x[:, 3]**3) + np.log(np.abs(x[:, 4]) + 1) + epi\n",
    "        self.x = x\n",
    "        self.y = y.reshape(-1, 1)\n",
    "\n",
    "    def data_split(self, percentage=0.2):\n",
    "        # 划分数据集为训练集和测试集\n",
    "        data = np.concatenate((self.x, self.y), axis=1)\n",
    "        shuffled_data = np.random.permutation(data)  # 随机打乱数据\n",
    "        n = len(self.x)\n",
    "        test_set = shuffled_data[:int(percentage * n), :]  # 测试集\n",
    "        training_set = shuffled_data[int(percentage * n):, :]  # 训练集\n",
    "        self.training = training_set\n",
    "        self.test = test_set\n",
    "\n",
    "    def KNN_regression(self, a_test, N):\n",
    "        # 单点的 KNN 回归\n",
    "        x_train = self.training[:, :-1]  # 训练集特征\n",
    "        y_train = self.training[:, -1]  # 训练集标签\n",
    "        dist = np.sum((a_test.reshape(1, -1) - x_train)**2, axis=1)  # 计算欧几里得距离的平方\n",
    "        indices = np.argsort(dist)[:N]  # 距离最近的 N 个点索引\n",
    "        return np.average(y_train[indices])  # 返回 N 个最近点的标签平均值\n",
    "\n",
    "    def Vectorized_KNN(self, N):\n",
    "        # 使用向量化方法对测试集进行 KNN 回归\n",
    "        test_features = self.test[:, :-1]  # 测试集特征\n",
    "        f = lambda x: self.KNN_regression(x, N)  # 将单点回归函数封装为 lambda 函数\n",
    "        predictions = np.apply_along_axis(f, axis=1, arr=test_features)  # 对每个测试样本应用回归\n",
    "        return predictions\n",
    "\n",
    "\n",
    "# 实例化并运行\n",
    "sample = 2000\n",
    "dim = 5\n",
    "num_class = 6\n",
    "my_class = KNN_Regression(sample, dim, num_class)\n",
    "\n",
    "# 生成数据\n",
    "my_class.data_generation()\n",
    "\n",
    "# 划分数据\n",
    "my_class.data_split()\n",
    "\n",
    "# 单点测试\n",
    "a_test_sample = my_class.test[0, :-1]  # 随机选择测试集中的一个点\n",
    "single_prediction = my_class.KNN_regression(a_test_sample, N=10)  # 对单个点进行回归\n",
    "print(f\"Prediction for a single test point: {single_prediction:.4f}\")\n",
    "\n",
    "# 测试集的向量化回归\n",
    "all_predictions = my_class.Vectorized_KNN(N=10)  # 对所有测试点进行回归\n",
    "print(f\"Predictions for all test points:\\n{all_predictions[:5]}\")  # print前 5 个预测结果"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
